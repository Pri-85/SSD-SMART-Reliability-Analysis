"""
SSD SMART Dataset â€“ Data Ingestion and Initial Inspection Script
Author: Priya
Purpose:
    This script performs the first phase of the SSD reliability analysis pipeline:
    Data Ingestion and Initial Exploratory Inspection. It loads the raw SMART dataset,
    standardizes column names, identifies metadata vs. telemetry attributes, converts
    numeric fields, evaluates missingness, and generates summary tables and visualizations.
    This step establishes the structural understanding required for normalization,
    feature engineering, and predictive modeling in later phases.

Workflow:
    1. Import required libraries (Pandas, NumPy, Seaborn, Matplotlib).
    2. Load the raw SMART dataset from CSV/Excel.
    3. Clean and standardize column names for consistency.
    4. Categorize columns into metadata, SMART health attributes, usage counters,
       and latency/performance metrics.
    5. Convert numeric fields (including scientific notation) to proper numeric types.
    6. Generate dataset-level summaries (shape, unique devices, attribute counts).
    7. Analyze missingness patterns and create an attribute overview table.
    8. Produce correlation heatmaps for telemetry attributes.
    9. Generate an automated EDA profiling report (HTML).

Tools Used:
    - Python 3.x
    - Pandas for data ingestion and cleaning
    - NumPy for numerical operations
    - Seaborn & Matplotlib for visualization
    - ydata-profiling for automated EDA reporting

Output:
    - Cleaned DataFrame in memory
    - Missingness summary
    - Attribute overview table
    - Correlation heatmap
    - Automated HTML EDA report saved to /reports/

This script is part of the reproducible SSD reliability benchmarking framework.
"""
